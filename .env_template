## Embed Endpoint of EventCenter module in Backend service
WEBHOOK_EVENT_CENTER_URL=http://localhost:8000
## Embed Endpoint of Intelligent_Threshold Agent service
WEBHOOK_INTELLIGENT_THRESHOLD_AGENT_URL=http://localhost:6001
## External Endpoint of EventCenter module in Backend service, need change localhost to public eip
WEBHOOK_EVENT_CENTER_EXTERNAL_URL=http://localhost:8000

# MONGO
MONGO_HOST=<your-mongo-host:27017>
MONGO_USER=example_user
MONGO_PASSWORD=change_me_before_prod

## Encrypt Secret Code Which Set in Lark OpenPlatform of bot, should leave blank
WEBHOOK_SECRET=

## Encryption Key for SecretStr, which used for decrypt/encrypt for SecretStr
ENCRYPTION_KEY=your_encryption_key


# Log Level, Default is INFO
LOG_LEVEL=DEBUG
# Log File name
LOG_FILE=veaiops.log


# OpenTelemetry
## If you don't want to start OpenTelemetry, you can set to false
OTEL_ENABLED=true
## Collector's OTLP gRPC endpoint
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
## Service Name
OTEL_SERVICE_NAME=VeAIOps
## Service Version
OTEL_SERVICE_VERSION=0.0.1
## Service Environment
OTEL_SERVICE_ENVIRONMENT=production
## Trace Ratio, in Production Env, suggest 0.1
OTEL_TRACE_ID_RATIO=1.0
## Delay milli seconds for schedule
OTEL_SCHEDULE_DELAY_MILLIS=5000
## Max Export Batch Size
OTEL_MAX_EXPORT_BATCH_SIZE=512
## Max Queue Size
OTEL_MAX_QUEUE_SIZE=2048

## BOT Channel. only support Lark by now
BOT_CHANNEL=Lark
## BOT ID. If you leave blank, you must add the bot by web console
BOT_ID=
## BOT Secret. If you leave blank, you must add the bot by web console
BOT_SECRET=
## BOT Template Card ID. you must manage this template id by web console
BOT_TEMPLATE_ID=

# Default Access Key for Volcengine
VOLCENGINE_AK=
# Default Secret Key of the above AK for Volcengine
VOLCENGINE_SK=
# Default TOS endpoint of Volcengine
VOLCENGINE_TOS_ENDPOINT=tos-cn-beijing.volces.com
# Default TOS region
VOLCENGINE_TOS_REGION=cn-beijing
# Default Extra kb collections
VOLCENGINE_EXTRA_KB_COLLECTIONS='[]'

# Agent, VeADK Configs
## Provider, should always be openai
LLM_PROVIDER=openai
## model name, if you use ark, you can fill with ep id
LLM_NAME=
## embedding model name, if you use ark, you can fill with ep id
LLM_EMBEDDING_NAME=
## API Key of ark or other LLM provider
LLM_API_KEY=
## base url of api, default value is https://ark.cn-beijing.volces.com/api/v3
LLM_API_BASE=https://ark.cn-beijing.volces.com/api/v3
